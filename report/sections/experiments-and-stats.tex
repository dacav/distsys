% ----------------------------------------------------------------------
\subsection{Tutorial: launching the application}
% ----------------------------------------------------------------------

Conventionally, an \Erlang\ \Keyword{application} has a target directory
in which binary object (\Path{.beam}) are pushed during compilation. This
directory is conventionally named \Path{ebin}, and the interpreter must be
aware of this position. So far, in order to launch the application, use
the following command line:
\begin{lstlisting}[language=bash]
$ erl -pa ebin
Erlang R14B03 (erts-5.8.4) [source] [64-bit] [smp:2:2] [rq:2]
[async-threads:0] [hipe] [kernel-poll:false]

Eshell V5.8.4  (abort with ^G)
1>
\end{lstlisting}

Before launching the application it may be necessary to re-compile the
modules:
\begin{lstlisting}[language=bash]
1> make:all([load]).
...
up_to_date
\end{lstlisting}

Then the application can be launched effectively:
\begin{lstlisting}[language=bash]
2> application:start(yuna).
Loading configuration...
Starting YUNA...
Starting main supervisor...
Starting peers pool...
Starting services...
ok
2012/1/4 3:30:59 <0.98.0>  Nodes started: N=500
2012/1/4 3:30:59 <0.98.0>  Preparing protocol...
2012/1/4 3:30:59 <0.98.0>  Nodes started. Letting them know each other...
...
\end{lstlisting}

After some time (depending on the execution) the process will stop:
\begin{lstlisting}[language=bash]
...
2012/1/4 3:32:4 <0.98.0>  Consensus (should) has been reached:
2012/1/4 3:32:4 <0.98.0>    Value false has been selected by 496 nodes
2012/1/4 3:32:4 <0.98.0>  Killing remaining processes...
2012/1/4 3:32:4 <0.98.0>  Terminating.
2012/1/4 3:32:4 <0.98.0>  Keeper finished.
\end{lstlisting}

This will produce the files containing the statistics. The name of the
file will depend, as explained in \Paragraph{subsub:ConfTechParams}, by a
prefix stored in the configuration variable. In this case (the prefix is
\emph{statfile} we have the following files:
\begin{lstlisting}[language=bash]
$ ls statfile_*
statfile_decision_count.log  statfile_est_node_count.log statfile_events.log  statfile_node_count.log
\end{lstlisting}

From this files we can produce easily the graph of the execution by
feeding the \emph{gnuplot} software with the prefix and the configuration
I've put in the \Path{priv} directory:
\begin{lstlisting}[language=bash]
$ gnuplot -e 'prefix="statfile"' priv/plot_stats.gnuplot
\end{lstlisting}

This will produce a \emph{pdf} file named after the prefix, in this case
\Path{statfile.pdf}. \Figure{fig:RunDefault} shows an example of graph.


% ----------------------------------------------------------------------
\subsection{Experiment: ambush to the coordinator}
% ----------------------------------------------------------------------

For testing purposes I patched the program in order to allow an external
process (ideally the \Erlang\ shell) to tamper the system before the
protocol runs.

I added an external boolean parameter, \VerbInline{start\_direct}, which
can be setted to \Const{false} obtaining the system to wait for user
interaction \emph{before} starting the protocol.

I also added a few calls to the \Const{gfd_keeper} component (which is
the \Keyword{specific keeper} for the process):
\begin{itemize}
\item   \Func{persist}{1} \\
        If called with parameter \Const{false} (disable
        \emph{persistence}), the \Keyword{keeper} is required to abort the
        protocol the number of failing nodes $f$ overcomes $n/2$;
\item   \Func{launch_consensus}{0} \\
        Launch the protocol if it's not running yet
        (not running if \VerbInline{start\_direct} = \Const{false});
\item   \Func{schedule_killing}{1} \\
        Allows the external project to declare a list of identifiers to be
        killed. For instance \Const{schedule_killing([1])} will kill the
        coordinator just before starting the protocol.
\end{itemize}

I wrote a small file which calls those functions. The file is directly
passed (as script) to an instance of the interpreter and run in batch
mode, so that the following sequence gets executed:
\begin{enumerate}
\item   Start the application;
\item   Tamper the execution by removing the \emph{persistence} of the
        \Keyword{keeper};
\item   Start the protocol;
\item   Put an \emph{\Erlang\ monitor} on the \Keyword{keeper} process
        (in order to get informed when the keeper terminates);
\item   Send a synchronous message to the \Keyword{logging server} (in
        order to build a \emph{causality relation} and ensure all event
        messages are served before retrieving data).
\end{enumerate}


At this point I wrote a little \emph{perl} script
(\PathSrc{priv/probtest.pl}) which runs the application with different
(incremental) values for the \PCrash\ parameter. For each probability
value the script runs a certain number of experiments. Then the same set
of experiments is ran with a small modification in the batch file,
scheduling the crash of the \emph{coordinator} before starting the
protocol.

The script retrieves the events (for instance the protocol startup and
stop time) at the end of each experiment. The collected data is so far
crunched and displayed on a picture by \emph{gnuplot}.

\ImageFW{pictures/many-runs}{
    Termination time for experiments. Experiments are run with incremental
    per-transmission failure probability ($x$ axis). As probability grows,
    the number of faulty nodes $f$ reaches $n/2$, thus the protocol is
    aborted. The pink line shows the average success time for each
    probability value. \See{\Paragraph{subsub:ManyRuns}}.
}{fig:ManyRuns}

\Figure{fig:ManyRuns} shows graphically the outcome of the described
experiment: I ran it starting from a probability $\PCrash = 0$
(perfect run, no crashes), incrementing \PCrash\ of $0.005$ at each
experiment. I also defined the stop condition the conjunction of $\PCrash
< 1$ and \emph{less than 5 consecutive fails}, so that the failure
probability remains in a reasonable interval.

Apart from probability, which is changing, the remaining configuration for
this experiment has been the following:
\begin{verbatim}
beaconwait 120
deliver_dist {random, uniform, []}
deliver_maxdel 1500
deliver_mindel 500
file_prefix statfile_default
keeper gfd_keeper
npeers 500
statpeers 0.01
tbeacon 500
tcleanup 20
tfail 10
tgossip 4
\end{verbatim}

\subsubsection{Considerations} \label{subsub:ManyRuns}

In a predictable manner, the experiments highlight a very strong
susceptibility to failure, even for small values of \PCrash:
each process, in fact, follows a \emph{geometric distribution}
\[
\Prob{\mbox{Crash at $k$-th transmission}} =
    \PCrash \cdot (1 - \PCrash)^{k - 1}
\]\[
\PrName{k} =
\Prob{\mbox{Being crashed after $k$ transmissions}} =
    \sum_{i = 1}^{k}\left( \PCrash \cdot (1 - \PCrash)^{i - 1} \right)
\]
and this distribution grows pretty quickly, which justifies the fact that
executions stop being meaningful for $\PCrash > 0.8$. In order to
determine the expected number of alive processes in time, a more in-depth
analysis should be achieved.

\Image{pictures/final}{
    Termination time for experiments. Different behaviors when the
    coordinator has been killed before value proposal. The points labelled
    \emph{consensus reached} can be seen in detail in
    \Figure{fig:ManyRuns}.
}{1}{fig:Final}

\Figure{fig:Final} shows the graph deriving from the described experiment;
\Figure{tab:Results} reports some statistics about the executions;
\Figure{fig:RunDefault} and \Figure{fig:RunDefaultTamper} show
respectively a normal and a tampered execution.

\ImageFW{pictures/run-default}{
    A run of the \emph{consensus} algorithm with the default settings.
    The green points (labelled \emph{est\_node\_count}) show the estimated
    number of nodes as provided by the \emph{Failure Detector} of the
    nodes enabled for statistical retrieval. The actual number of nodes is
    500 (no nodes crashed during the experiment). The \emph{start protocol}
    and the \emph{end protocol} labels show respectively the startup
    instant of the \emph{consensus} protocol and the instant in which the
    nodes achieved the agreement.
}{fig:RunDefault}

\ImageFW{pictures/run-default-nocoord}{
    A run of the \emph{tampered consensus} algorithm with the default
    settings. The experiment follows the same characteristics of the one
    showed in \Figure{fig:RunDefault}, except the coordinator is killed
    just before the protocol starts. We can appreciate the difference in
    termination time.
}{fig:RunDefaultTamper}

\begin{figure}[tb!]
    \centering

    \subfigure[Protocol termination time for normal consensus]{
        \begin{tabular}{lrr}
        \toprule
        {Probability} & {Avg [ms]} & {Max [ms]} \\
        \midrule
        0       &  4918 & 10285 \\
        0.005   &  3261 & 4274 \\
        0.01    &  3032 & 4488 \\
        0.015   &  3394 & 7572 \\
        0.02    &  4112 & 6920 \\
        0.025   & 23031 & 62993 \\
        0.03    &  4723 & 9782 \\
        0.035   & 17863 & 32955 \\
        0.04    &  2327 & 2600 \\
        0.055   &  2385 & 2385 \\
        \bottomrule
        \end{tabular}
    }

    \subfigure[Protocol termination time for tampered consensus]{
        \begin{tabular}{lrr}
        \toprule
        {Probability} & {Avg [ms]} & {Max [ms]} \\
        \midrule
        0       &  74305 & 99863 \\
        0.005   & 116259 & 216993 \\
        0.01    &  78656 & 106305 \\
        0.015   &  68723 & 86209 \\
        0.02    &  56247 & 71610 \\
        0.025   &  35976 & 47802 \\
        0.03    &   5978 & 5978 \\
        \bottomrule
        \end{tabular}
    }

    \caption{\emph{Comparison between normal runs of the \emph{Consensus}
             algorithm and runs in which the coordinator in charge has
             been killed before value proposal.}}
    \label{tab:Results}
\end{figure}
